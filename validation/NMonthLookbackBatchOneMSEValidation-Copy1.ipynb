{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a1df9-6948-4e26-9515-e7d48bcbc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_excel('../data/state_month_overdose.xlsx')\n",
    "\n",
    "df['Deaths'] = df['Deaths'].apply(lambda x: 0 if x == 'Suppressed' else int(x))\n",
    "\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "\n",
    "df = df.reset_index() #2015/01\n",
    "df['Month Code'] = pd.to_datetime(df['Month Code'])#.reset_index() #2015-01-01\n",
    "# df.set_index('Month', inplace=True)\n",
    "df = df.groupby(['Month']).agg({'Deaths': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "train = df[df['Month'] <= '2019-01-01']\n",
    "test = df[(df['Month'] >= '2019-01-01') & (df['Month'] <= '2019-12-01')]\n",
    "testog = test\n",
    "test = test.reset_index().drop(columns = ['index'])\n",
    "\n",
    "\n",
    "\n",
    "# Modify the create_dataset function to use a lookback of 3 months\n",
    "def create_dataset(dataset, look_back=3):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset.iloc[i:(i + look_back)]  # Collect the previous 'look_back' months\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset.iloc[i + look_back])  # The target is the subsequent month\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "look_back = 3\n",
    "\n",
    "extended_test = pd.concat([train.iloc[-look_back:], test])\n",
    "\n",
    "# Prepare LSTM datasets\n",
    "trainX, trainY = create_dataset(train['Deaths'], look_back)\n",
    "testX, testY = create_dataset(extended_test['Deaths'], look_back)\n",
    "\n",
    "\n",
    "# Reshape inputs to match LSTM input requirements (samples, time_steps, features)\n",
    "trainX = trainX.reshape((trainX.shape[0], look_back, 1))\n",
    "testX = testX.reshape((testX.shape[0], look_back, 1))\n",
    "\n",
    "# Rebuild the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# Updated generate_forecast function to handle 3-month lookback\n",
    "def generate_forecast(model, initial_sequence, num_predictions=12, look_back=3):\n",
    "    predictions = []\n",
    "    for _ in range(num_predictions):\n",
    "        # Generate the next prediction\n",
    "        next_prediction = model.predict(initial_sequence)\n",
    "        predictions.append(next_prediction[0][0])\n",
    "        \n",
    "        # Update the sequence with the new prediction\n",
    "        new_sequence = np.append(initial_sequence[0, 1:], [[next_prediction[0][0]]], axis=0)\n",
    "        initial_sequence = new_sequence.reshape((1, look_back, 1))\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Prepare the initial sequence for forecasting using the last `look_back` months from training\n",
    "initial_sequence = trainX[-1].reshape((1, look_back, 1))\n",
    "\n",
    "# Generate test predictions with the updated lookback logic\n",
    "testPredict = generate_forecast(model, initial_sequence, num_predictions=testY.shape[0], look_back=look_back)\n",
    "trainPredict = model.predict(trainX)\n",
    "\n",
    "# Flatten predictions for visualization and evaluation\n",
    "testPredictlst = testPredict.flatten().tolist()\n",
    "trainPredictlst = trainPredict.flatten().tolist()\n",
    "\n",
    "# Combine actual data and predictions\n",
    "combined_array = [0] * look_back + trainPredictlst + testPredictlst\n",
    "df['LSTM Predictions'] = combined_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sarima_model = SARIMAX(train['Deaths'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "sarima_predictions = sarima_result.predict(start=0, end=len(train) + len(test) - 1, dynamic=False)\n",
    "\n",
    "df['SARIMA Predictions'] = sarima_predictions\n",
    "\n",
    "df.to_csv(f'/tables/{look_back}month_predictionresults_batch_1_loss_mse.csv')\n",
    "\n",
    "plottable = df.iloc[1:] #only taking rows with predictions so excluding part included in first lookback\n",
    "plottable.set_index('Month', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e31ee7-aa75-40a7-ad50-f039aff29415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['Month'] >= '2019-01-01') & (df['Month'] <= '2019-12-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29ed99-8f5a-4fa7-8ec1-6282d760d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3893c-f5b6-4b36-bf6c-f2fc1e1afeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a97c8f-041e-4ce4-a3f0-7c7dfa2fa2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testY))\n",
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b57b8c-324b-487d-8376-e77adec9f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854ec82-43dd-49d6-a487-1df12097c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testPredict))\n",
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf0744-3f4b-464f-9c05-bdb7ad959ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict[:len(testY)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413d42a-0e74-4972-86e5-5d3b9037edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sarima_predictions[1:len(trainPredict)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965014d-0297-401b-a7e4-52491dcad609",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_predictions[len(trainPredict):len(trainPredict)+len(testY)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b049a26-be24-4333-b5a2-9befd3cdeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3384f-dda2-4285-a740-947482f01fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM calculate root mean squared error\n",
    "print('LSTM')\n",
    "trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY[:len(testPredict)], testPredict[:len(testY)]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "#SARIMA Error Metrics\n",
    "print('SARIMA')\n",
    "trainScore = np.sqrt(mean_squared_error(trainY, sarima_predictions[1:len(trainPredict)+1]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY, sarima_predictions[len(trainPredict):len(trainPredict)+len(testY)]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plottable.index, plottable['Deaths'], label='Actual Data', color='blue')\n",
    "plt.plot(plottable.index, plottable['LSTM Predictions'], label='LSTM Predictions', color='red')\n",
    "plt.plot(plottable.index, plottable['SARIMA Predictions'], label='SARIMA Predictions', color='green')\n",
    "plt.title('Deaths: Actual vs LSTM vs SARIMA Predictions (Without Scaling)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Deaths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0c2ab-a23f-4624-99ba-c8a680bd2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888d923-cf95-4c90-951d-fa1144548da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_intervals(predictions, alpha=0.05):\n",
    "    # Calculate mean and standard deviation\n",
    "    mean_pred = np.mean(predictions)\n",
    "    std_pred = np.std(predictions)\n",
    "    \n",
    "    # Calculate the z-score for the confidence level\n",
    "    z_score = 1.96  # for 95% confidence\n",
    "    margin_of_error = z_score * (std_pred / np.sqrt(len(predictions)))\n",
    "    \n",
    "    lower_bound = predictions - margin_of_error\n",
    "    upper_bound = predictions + margin_of_error\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "sarimaTestPredict = df[df['Month'] > '2020-01-01']['SARIMA Predictions']\n",
    "# Calculate confidence intervals\n",
    "lower_bound_test, upper_bound_test = calculate_confidence_intervals(testPredict)\n",
    "lower_bound_sarima, upper_bound_sarima = calculate_confidence_intervals(sarimaTestPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e05d7-1d55-4e57-9c3e-fe38273b73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimaTestPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288194b-46e4-44b6-927c-97edc7f4a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c7d03-7766-411e-9ce7-403514a2f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(lower1, upper1, lower2, upper2):\n",
    "    # Initialize overlap count\n",
    "    overlap_count = 0\n",
    "\n",
    "    for l1, u1, l2, u2 in zip(lower1, upper1, lower2, upper2):\n",
    "        # Check for overlap\n",
    "        if u1 >= l2 and l1 <= u2:\n",
    "            overlap_count += 1\n",
    "\n",
    "    # Calculate percent overlap\n",
    "    percent_overlap = (overlap_count / len(lower1)) * 100\n",
    "    return percent_overlap\n",
    "\n",
    "# Calculate percent overlap\n",
    "percent_overlap = calculate_overlap(lower_bound_test, upper_bound_test, lower_bound_sarima, upper_bound_sarima)\n",
    "\n",
    "print(f'Percent Overlap: {percent_overlap:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ecb3f-2b07-4bd6-9f0e-a64422be749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1a113-2493-4ae7-adc8-06e287b8d486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
