{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac14476-8997-4dca-a6c6-22bd1862355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 12:58:04.878521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_146104/2976891395.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Month'] = pd.to_datetime(df['Month'])\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734641886.321060  146104 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-19 12:58:06.679096: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-12-19 12:58:07.885084: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-19 12:58:07.921940: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-19 12:58:07.965516: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-19 12:58:08.041835: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-19 12:58:08.192365: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-19 12:58:08.533582: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-19 12:58:10.158888: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-12-19 12:58:12.422565: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f39185e0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f39182b75b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukikrishna/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(1,), dtype=float32). Expected shape (None, 12, 1), but input has incompatible shape (1,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1,), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Add LSTM predictions to DataFrame\u001b[39;00m\n\u001b[1;32m    116\u001b[0m initial_sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([trainPred[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m--> 117\u001b[0m testPredict \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m trainPredictlst \u001b[38;5;241m=\u001b[39m trainPred\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    119\u001b[0m testPredictlst \u001b[38;5;241m=\u001b[39m testPredict\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mgenerate_forecast\u001b[0;34m(model, initial_sequence, num_predictions, look_back)\u001b[0m\n\u001b[1;32m     29\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_predictions):\n\u001b[0;32m---> 31\u001b[0m     next_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(next_prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     33\u001b[0m     new_sequence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(initial_sequence[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:], [[next_prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/functional.py:264\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(1,), dtype=float32). Expected shape (None, 12, 1), but input has incompatible shape (1,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(1,), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read data\n",
    "df = pd.read_excel('data/state_month_overdose.xlsx')\n",
    "df['Deaths'] = df['Deaths'].apply(lambda x: 0 if x == 'Suppressed' else int(x))\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df = df.groupby(['Month']).agg({'Deaths': 'sum'}).reset_index()\n",
    "\n",
    "# Create dataset function\n",
    "def create_dataset(dataset, look_back=3):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset.iloc[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset.iloc[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Function for generating forecast with LSTM\n",
    "def generate_forecast(model, initial_sequence, num_predictions=12, look_back=3):\n",
    "    predictions = []\n",
    "    for _ in range(num_predictions):\n",
    "        next_prediction = model.predict(initial_sequence)\n",
    "        predictions.append(next_prediction[0][0])\n",
    "        new_sequence = np.append(initial_sequence[0, 1:], [[next_prediction[0][0]]], axis=0)\n",
    "        initial_sequence = new_sequence.reshape((1, look_back, 1))\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Function for calculating confidence intervals\n",
    "def calculate_confidence_intervals(predictions, alpha=0.05):\n",
    "    mean_pred = np.mean(predictions)\n",
    "    std_pred = np.std(predictions)\n",
    "    z_score = 1.96  # for 95% confidence\n",
    "    margin_of_error = z_score * (std_pred / np.sqrt(len(predictions)))\n",
    "    lower_bound = predictions - margin_of_error\n",
    "    upper_bound = predictions + margin_of_error\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Function to calculate overlap between two sets of confidence intervals\n",
    "def calculate_overlap(lower1, upper1, lower2, upper2):\n",
    "    overlap_count = 0\n",
    "    for l1, u1, l2, u2 in zip(lower1, upper1, lower2, upper2):\n",
    "        if u1 >= l2 and l1 <= u2:\n",
    "            overlap_count += 1\n",
    "    percent_overlap = (overlap_count / len(lower1)) * 100\n",
    "    return percent_overlap\n",
    "\n",
    "# Cross-validation loop for different lookbacks and validation periods\n",
    "validation_periods = [('2015-01-01', '2017-01-01'), ('2017-01-01', '2019-01-01'), ('2019-01-01', '2020-01-01')]  # Example periods\n",
    "look_back_periods = [3, 6, 12]  # Example lookback periods\n",
    "results = []\n",
    "\n",
    "# Loop through validation periods and lookbacks\n",
    "for val_start, val_end in validation_periods:\n",
    "    for look_back in look_back_periods:\n",
    "        train = df[df['Month'] < val_start]\n",
    "        validation = df[(df['Month'] >= val_start) & (df['Month'] < val_end)]\n",
    "        test = df[df['Month'] >= val_end]\n",
    "\n",
    "        extended_validation = pd.concat([train.iloc[-look_back:], validation])\n",
    "        extended_test = pd.concat([validation.iloc[-look_back:], test])\n",
    "\n",
    "        trainX, trainY = create_dataset(train['Deaths'], look_back)\n",
    "        valX, valY = create_dataset(extended_validation['Deaths'], look_back)\n",
    "        testX, testY = create_dataset(extended_test['Deaths'], look_back)\n",
    "\n",
    "        trainX = trainX.reshape((trainX.shape[0], look_back, 1))\n",
    "        valX = valX.reshape((valX.shape[0], look_back, 1))\n",
    "        testX = testX.reshape((testX.shape[0], look_back, 1))\n",
    "\n",
    "        # Build and train LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(look_back, 1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=0)\n",
    "\n",
    "        # Generate validation predictions with LSTM\n",
    "        valPred = model.predict(valX).flatten()\n",
    "        lstm_mse = mean_squared_error(valY, valPred)\n",
    "        results.append({'Validation Period': f\"{val_start} to {val_end}\",\n",
    "                        'Look-back': look_back, 'LSTM MSE': lstm_mse})\n",
    "\n",
    "# Save LSTM results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('eval_test_kfold_cross_validation_lookback_results.csv', index=False)\n",
    "\n",
    "# Identify best model\n",
    "best_model = results_df.loc[results_df['LSTM MSE'].idxmin()]\n",
    "best_val_start, best_val_end = best_model['Validation Period'].split(' to ')\n",
    "best_look_back = best_model['Look-back']\n",
    "\n",
    "# Train and test with best model\n",
    "full_train = df[df['Month'] < best_val_end]\n",
    "extended_test = pd.concat([full_train.iloc[-best_look_back:], test])\n",
    "\n",
    "trainX, trainY = create_dataset(full_train['Deaths'], best_look_back)\n",
    "testX, testY = create_dataset(extended_test['Deaths'], best_look_back)\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], best_look_back, 1))\n",
    "testX = testX.reshape((testX.shape[0], best_look_back, 1))\n",
    "\n",
    "model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=0)\n",
    "testPred = model.predict(testX).flatten()\n",
    "trainPred = model.predict(trainX).flatten()\n",
    "\n",
    "# Add LSTM predictions to DataFrame\n",
    "initial_sequence = np.array([trainPred[-1]])\n",
    "testPredict = generate_forecast(model, initial_sequence, num_predictions=len(test))\n",
    "trainPredictlst = trainPred.flatten().tolist()\n",
    "testPredictlst = testPredict.flatten().tolist()\n",
    "combined_array = [0] + trainPredictlst + testPredictlst\n",
    "df['LSTM Predictions'] = combined_array\n",
    "\n",
    "# Train SARIMA Model\n",
    "sarima_model = SARIMAX(full_train['Deaths'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12),\n",
    "                       enforce_stationarity=False, enforce_invertibility=False)\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "sarima_predictions = sarima_result.predict(start=0, end=df.shape[0] - 1, dynamic=False)\n",
    "df['SARIMA Predictions'] = sarima_predictions\n",
    "\n",
    "sarimaTestPredict = df[df['Month'] >= best_val_end]['SARIMA Predictions']\n",
    "\n",
    "# Calculate metrics for best model\n",
    "final_test_results = {\n",
    "    'Best Validation Period': f\"{best_val_start} to {best_val_end}\",\n",
    "    'Best Look-back': best_look_back,\n",
    "    'LSTM Train MAPE': mean_absolute_percentage_error(trainY, trainPred),\n",
    "    'LSTM Train MSE': mean_squared_error(trainY, trainPred),\n",
    "    'LSTM Test MAPE': mean_absolute_percentage_error(testY, testPred),\n",
    "    'LSTM Test MSE': mean_squared_error(testY, testPred),\n",
    "    'SARIMA Test MAPE': mean_absolute_percentage_error(testY, sarimaTestPredict),\n",
    "    'SARIMA Test MSE': mean_squared_error(testY, sarimaTestPredict)\n",
    "}\n",
    "\n",
    "pd.DataFrame([final_test_results]).to_csv('eval_test_results.csv', index=False)\n",
    "\n",
    "# Plot Results\n",
    "plottable = df.iloc[1:]  # Exclude rows used for the first lookback\n",
    "plottable.set_index('Month', inplace=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plottable.index, plottable['Deaths'], label='Actual Data', color='blue')\n",
    "plt.plot(plottable.index, plottable['SARIMA Predictions'], label='SARIMA Predictions', color='green')\n",
    "plt.plot(plottable.index, plottable['LSTM Predictions'], label='LSTM Predictions', color='red')\n",
    "plt.title('Deaths: Actual vs LSTM vs SARIMA Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Deaths')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4da3d1b-789f-4b51-9040-8956bebc1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8e5c3d-05d0-4e99-a94f-481961eef31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4478.923], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6500fc-cb12-4005-b33e-93c3a16f226a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
